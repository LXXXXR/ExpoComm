# --- IQL specific parameters ---

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 5000 #
evaluation_epsilon: 0.0
runner: "episode"

batch_size: 64
buffer_size: 2000

# update the target network every {} episodes
target_update_interval_or_tau: 200

mac: "ExpoComm_mac"
topk_neighbors: 8 # including itself
one_peer: True
agent: "ExpoComm_one_peer_cont" # Default rnn agent
obs_agent_id: True
obs_last_action: True
obs_individual_obs: False

# use the Q_Learner to train

agent_output_type: "q"
learner: "cont_q_learner"
aux_coef: 0.1 # Coefficient for auxiliary loss
temperature: 0.07 # value from https://github.com/sthalles/SimCLR/blob/1848fc934ad844ae630e6c452300433fe99acfd9/run.py#L49
neg_num: 20
standardise_returns: False
standardise_rewards: True
double_q: True
mixer: "qmix"
use_rnn: True
mixing_embed_dim: 64
hypernet_layers: 2
hypernet_embed: 64

gamma: 0.95 

pos_flag: False

name: "qmix_ExpoComm_one_peer_n8_cont"